{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f0f3aa-0c59-4252-b654-a3e8430217b1",
   "metadata": {},
   "source": [
    "#  Ensemble Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c415e-a7ff-45ee-bdaa-01211e226d32",
   "metadata": {},
   "source": [
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33640491-0a02-448f-a947-c1abe323e0a7",
   "metadata": {},
   "source": [
    "# Q1. What is an ensemble technique in machine learning?\n",
    "# Q3. What is bagging?\n",
    "# Q4. What is boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85deeb4c-308d-4882-83b4-8dc292295d81",
   "metadata": {},
   "source": [
    "In ensemble technique, is basically combine the multiple models and geting their predictions for devploping their outcome.in the case of classifier, the outcome or prediction of the ensemble technique is accordng to the features, who are majority and for regresser it is considered by the \n",
    "avrage of the outcome of the various models.\n",
    "\n",
    "  as it takes the multiple models for their prediction, so the accuracay and performance of our model will increased.However there are multiple ensemble techniques , some of the common are below;\n",
    "  \n",
    "- **Bagging** : It is used for classification and regression problems. In this technique, we split our dataset in the multiple samples and train these samples by multiple models according to our requairments ..ie...decision tree, Svm , Nive bayes. and getting the predictions from each models according to train data. Then we aggregate the outcoms of all models , and by these model predictions voting we get a specific output. it is also called bootstrap agrigation.\n",
    "\n",
    "- **Boosting** :Boosting also combines multiple weak learners (typically simple models) to create a strong learner. In boosting, models are trained sequentially, and each subsequent model focuses on the mistakes made by the previous ones.There are various types ofnBoosting as Adaboost, Gradient boost, Xgboost. and they are using to solve both kind of problems classifier and regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d8dbe-72d5-4d45-b45a-cb3adcbf9fb0",
   "metadata": {},
   "source": [
    "# Q2. Why are ensemble techniques used in machine learning?\n",
    "# Q5. What are the benefits of using ensemble techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7099c05f-5385-4828-995a-aced0aec602c",
   "metadata": {},
   "source": [
    "There are various reasons for using the ensemble techniques in meachine learning, we disscussed these reason one by one in below section:\n",
    "\n",
    "**Improved performance :** As we know that ensembles techniques takes multiple models to make their decision for prediction of the dependent feature. It is very obvious then when it takes the potentiallity of multiple models then then it will become more powerfull in terms of performance.\n",
    "\n",
    "**Reduced Overfitting :** Ensemble techniques, specially bagging techniques used the differnt-different samples of data, which is eased to model for moving towards overfitting.\n",
    "\n",
    "**Handling Complex Relationships:** ensembles can capture complex relationships in the data by combining the strengths of different models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710676b3-fad0-4f45-a12e-51ea2bba5279",
   "metadata": {},
   "source": [
    "# Q6. Are ensemble techniques always better than individual models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9303ca1e-eb23-4d2a-b01f-6ac3cb1f9775",
   "metadata": {},
   "source": [
    "Ensemble techniques are often performe well than the individual model but it is unfair to say that ensemble techniques are always better than individual models. It is depend on the conditions of the data , that what is the best technique for predicting the outputs.\n",
    "Here are certain conditions where individual models can be preffered over the ensemble techniques:\n",
    "\n",
    "**Computational Constraints:** Ensembles are computationally expensive as they are processing the multiple models , so when computaional constraints are there, we should go for individual models.\n",
    "\n",
    "**Simplicity and Interpretability:** When the problem is not so complex and seem like simple , in that case , sometimes ensembles are intepret them in a crucial way. To avoide such problems we can use the individual models.\n",
    "\n",
    "**Resource Limitations:**  In resource-constrained environments, deploying and maintaining multiple models in an ensemble may be challenging. In that senerio we rembers the individual models as our great option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25281be7-bb83-4034-ace1-2f48e49424d9",
   "metadata": {},
   "source": [
    "# Q7. How is the confidence interval calculated using bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6249af7-316f-4baf-aaa0-5d646f4309dd",
   "metadata": {},
   "source": [
    "# Q8. How does bootstrap work and What are the steps involved in bootstrap?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e528144b-576a-41a3-89a1-d36db1616527",
   "metadata": {},
   "source": [
    " Bootstrap is a resampling technique that allows you to estimate the sampling distribution of a statistic by repeatedly resampling with replacement from the observed data. Here are the steps that are involved in bootstrap\n",
    "- Start with your original dataset of size n.\n",
    "- Resampling\n",
    "- Statistic Calculation\n",
    "- Examine the distribution of the statistic calculated from the bootstrap samples. \n",
    "- **Confidence Interval Construction:** Calculate the desired percentiles of the distribution of the statistic. The most common choice is the 95% confidence interval, which involves finding the 2.5th and 97.5th percentiles of the bootstrap distribution.\n",
    "- Analyze the bootstrap distribution and confidence interval to make inferences about the population parameter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3a9848-9b49-491a-8266-f8981dd3e10f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7833eedd-b22f-4a8e-b276-34871713fcfb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
